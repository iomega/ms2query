{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e5800d",
   "metadata": {},
   "source": [
    "# Create classifier classifications\n",
    "This notebook can be used to create a csv file with classifier classifications for a file with spectra from GNPS.\n",
    "This relies on the API of GNPS, so it will only return the classifications for smiles known by GNPS. \n",
    "\n",
    "#### This file is not needed to run MSQuery, but returns extra information for the found metabolites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a97b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import urllib\n",
    "import time\n",
    "from sys import argv\n",
    "from typing import List, Union, Dict\n",
    "from matchms.typing import SpectrumType\n",
    "from ms2query.utils import load_pickled_file\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5be51",
   "metadata": {},
   "source": [
    "Load in spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "749d4292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all spectra available (so train, test and validation)\n",
    "spectrum_file_name = \"replace_with_file_location_with_all_gnps_spectra\"\n",
    "spectra = load_pickled_file(spectrum_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a62622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_url_request(url: str) -> [bytes, None]:\n",
    "    \"\"\"\n",
    "    Do url request and return bytes from .read() or None if HTTPError is raised\n",
    "    :param url: url to access\n",
    "    :return: open file or None if request failed\n",
    "    \"\"\"\n",
    "    time.sleep(1)  # to not overload the api\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as inf:\n",
    "            result = inf.read()\n",
    "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
    "        # apparently the request failed\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_json_cf_results(raw_json: bytes) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract the wanted CF classes from bytes version (open file) of json str\n",
    "    Names of the keys extracted in order are:\n",
    "    'kingdom', 'superclass', 'class', 'subclass', 'direct_parent'\n",
    "    List elements are concatonated with '; '.\n",
    "    :param raw_json: Json str as a bytes object containing ClassyFire\n",
    "        information\n",
    "    :return: Extracted CF classes\n",
    "    \"\"\"\n",
    "    wanted_info = []\n",
    "    cf_json = json.loads(raw_json)\n",
    "    wanted_keys_list_name = ['kingdom', 'superclass', 'class',\n",
    "                             'subclass', 'direct_parent']\n",
    "    for key in wanted_keys_list_name:\n",
    "        info_dict = cf_json.get(key, \"\")\n",
    "        info = \"\"\n",
    "        if info_dict:\n",
    "            info = info_dict.get('name', \"\")\n",
    "        wanted_info.append(info)\n",
    "\n",
    "    return wanted_info\n",
    "\n",
    "\n",
    "def get_json_npc_results(raw_json: bytes) -> List[str]:\n",
    "    \"\"\"Read bytes version of json str, extract the keys in order\n",
    "    Names of the keys extracted in order are:\n",
    "    class_results, superclass_results, pathway_results, isglycoside.\n",
    "    List elements are concatonated with '; '.\n",
    "    :param raw_json:Json str as a bytes object containing NPClassifier\n",
    "        information\n",
    "    :return: Extracted NPClassifier classes\n",
    "    \"\"\"\n",
    "    wanted_info = []\n",
    "    cf_json = json.loads(raw_json)\n",
    "    wanted_keys_list = [\"class_results\", \"superclass_results\",\n",
    "                        \"pathway_results\"]\n",
    "    # this one returns a bool not a list like the others\n",
    "    last_key = \"isglycoside\"\n",
    "\n",
    "    for key in wanted_keys_list:\n",
    "        info_list = cf_json.get(key, \"\")\n",
    "        info = \"\"\n",
    "        if info_list:\n",
    "            info = \"; \".join(info_list)\n",
    "        wanted_info.append(info)\n",
    "\n",
    "    last_info_bool = cf_json.get(last_key, \"\")\n",
    "    last_info = \"0\"\n",
    "    if last_info_bool:\n",
    "        last_info = \"1\"\n",
    "    wanted_info.append(last_info)\n",
    "\n",
    "    return wanted_info\n",
    "\n",
    "\n",
    "def get_cf_classes(smiles: str, inchi: str) -> Union[None, List[str]]:\n",
    "    \"\"\"Get ClassyFire classes through GNPS API\n",
    "    :param smiles: Smiles for the query spectrum\n",
    "    :param inchi: Inchikey for the query spectrum\n",
    "    :return: ClassyFire classes if possible\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    # lookup CF with smiles\n",
    "    if smiles:\n",
    "        url_base = \"https://gnps-structure.ucsd.edu/classyfire?smiles=\"\n",
    "        url_smiles = url_base + smiles\n",
    "        smiles_result = do_url_request(url_smiles)\n",
    "\n",
    "        # read CF result\n",
    "        if smiles_result is not None:\n",
    "            result = get_json_cf_results(smiles_result)\n",
    "\n",
    "    if not result:\n",
    "        # do a second try with inchikey\n",
    "        if inchi:\n",
    "            url_inchi = \\\n",
    "                f\"https://gnps-classyfire.ucsd.edu/entities/{inchi}.json\"\n",
    "            inchi_result = do_url_request(url_inchi)\n",
    "\n",
    "            # read CF result from inchikey lookup\n",
    "            if inchi_result is not None:\n",
    "                result = get_json_cf_results(inchi_result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_npc_classes(smiles: str) -> Union[None, List[str]]:\n",
    "    \"\"\"Get NPClassifier classes through GNPS API\n",
    "    :param smiles: Smiles for the query spectrum\n",
    "    :return: NPClassifier classes if possible\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    # lookup NPClassifier with smiles\n",
    "    if smiles:\n",
    "        url_base_npc = \"https://npclassifier.ucsd.edu/classify?smiles=\"\n",
    "        url_smiles_npc = url_base_npc + smiles\n",
    "        smiles_result_npc = do_url_request(url_smiles_npc)\n",
    "\n",
    "        # read NPC result\n",
    "        if smiles_result_npc is not None:\n",
    "            result = get_json_npc_results(smiles_result_npc)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_classes(spectra: List[SpectrumType], out_file: str):\n",
    "    \"\"\"\n",
    "    Write classes for the unique compounds (inchikeys) in spectra via GNPS API\n",
    "    :param spectra: list of spectra\n",
    "    :param out_file: location of output file\n",
    "    :return: dict {inchikey: [smiles, cf_classes, npc_classes, [spectrum_ids]]}\n",
    "    \"\"\"\n",
    "    print(\"\\nRetrieving classes from GNPS API\")\n",
    "    out_txt = write_header(out_file)  # init out file with header\n",
    "    missed_cfs = 0\n",
    "    missed_npcs = 0\n",
    "    missed_spectra = 0\n",
    "    inchikey_set = set()\n",
    "    for i, spec in tqdm(enumerate(spectra)):\n",
    "        if i % 5000 == 0 and not i == 0:\n",
    "            print(\n",
    "                f\"{i} spectra done, {len(inchikey_set)} inchikeys collected\")\n",
    "\n",
    "        # get info for spectrum\n",
    "        spec_id = spec.metadata.get(\"spectrum_id\")\n",
    "        if not spec_id:  # as a check if it will have id under different name\n",
    "            spec_id = spec.metadata.get(\"spectrumid\")\n",
    "        inchi = spec.metadata.get(\"inchikey\")\n",
    "        if not inchi:\n",
    "            print(f\"\\t#{i} {spec_id} no inchikey\")\n",
    "            missed_spectra += 1\n",
    "            continue\n",
    "        smiles = spec.metadata.get(\"smiles\")\n",
    "        if not smiles:\n",
    "            smiles = \"\"  # smiles can be None in metadata\n",
    "\n",
    "        if inchi not in inchikey_set:  # inchikey didn't occur yet\n",
    "            smiles = smiles.strip(' ')\n",
    "            safe_smiles = urllib.parse.quote(smiles)  # url encoding\n",
    "            cf_result = get_cf_classes(safe_smiles, inchi)\n",
    "            if not cf_result:\n",
    "                missed_cfs += 1\n",
    "                # num classes we want, if they are changed, change this number\n",
    "                cf_result = ['' for _ in range(5)]\n",
    "\n",
    "            npc_result = get_npc_classes(safe_smiles)\n",
    "            if not npc_result:\n",
    "                # num classes we want, if they are changed, change this number\n",
    "                npc_result = ['' for _ in range(4)]\n",
    "            # pathway, im assuming this one occurs the most if missing others\n",
    "            if not npc_result[2]:\n",
    "                missed_npcs += 1\n",
    "\n",
    "            # combine results\n",
    "            combined_result = [smiles] + cf_result + npc_result\n",
    "            write_class_info(inchi, combined_result, out_txt)\n",
    "            inchikey_set.add(inchi)\n",
    "\n",
    "    print(\"Retrieved ClassyFire classes for \" +\n",
    "          f\"{len(inchikey_set)-missed_cfs} inchikeys, missing {missed_cfs}\")\n",
    "    print(\"Retrieved NPClassifier classes for \" +\n",
    "          f\"{len(inchikey_set)-missed_npcs} inchikeys, missing {missed_npcs}\")\n",
    "    print(f\"Could not retrieve class data for {missed_spectra} spectra \" +\n",
    "          \"because of missing inchikeys\")\n",
    "    print(f\"\\nWrote output to {out_txt}\")\n",
    "    return inchikey_set\n",
    "\n",
    "\n",
    "def write_header(out_file: str) -> str:\n",
    "    \"\"\"Write classes to out_file, returns out_file with possible .txt added\n",
    "    :param out_file: location of output file\n",
    "    \"\"\"\n",
    "    if not out_file.endswith('.txt'):\n",
    "        out_file += '.txt'\n",
    "\n",
    "    header_list = [\n",
    "        'inchi_key', 'smiles', 'cf_kingdom',\n",
    "        'cf_superclass', 'cf_class', 'cf_subclass', 'cf_direct_parent',\n",
    "        'npc_class_results', 'npc_superclass_results', 'npc_pathway_results',\n",
    "        'npc_isglycoside']\n",
    "    with open(out_file, 'w') as outf:\n",
    "        outf.write(\"{}\\n\".format('\\t'.join(header_list)))\n",
    "    return out_file\n",
    "\n",
    "\n",
    "def write_class_info(inchikey: str,\n",
    "                     class_info: List[str],\n",
    "                     out_file: str):\n",
    "    \"\"\"Write classes to out_file\n",
    "    :param inchikey: inchikey\n",
    "    :param class_info: list [smiles, cf_classes, npc_classes]\n",
    "    :param out_file: location of output file\n",
    "    \"\"\"\n",
    "    with open(out_file, 'a') as outf:\n",
    "        write_str = [inchikey] + class_info\n",
    "        outf.write(\"{}\\n\".format('\\t'.join(write_str)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1bca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of spectra: \", len(spectra))\n",
    "output_file = \"C:/Users/jonge094/PycharmProjects/PhD_MS2Query/ms2query/data/test_dir/classifiers\"\n",
    "passed_inchikeys = get_classes(spectra, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
